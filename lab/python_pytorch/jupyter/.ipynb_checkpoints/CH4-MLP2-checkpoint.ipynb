{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 多层感知器的nn.module实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import init\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import d2lzh_pytorch as d2l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### #### 定义网络，网络参数初始化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (fc1): Linear(in_features=784, out_features=256, bias=True)\n",
      "  (fc2): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (fc3): Linear(in_features=128, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#  每张图像大小 28 x 28 =784\n",
    "#  一共10类，输出等于类别数量\n",
    "#  中间的隐层 256 个\n",
    "# 可以选择不同的激活函数\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        #nn.Module子类的函数必须在构造函数中执行父类的构造函数\n",
    "        #下式等价于nn.Module.__init__(self)\n",
    "        super(MLP,self).__init__()\n",
    "        self.fc1 = nn.Linear(784,256)\n",
    "        self.fc2 = nn.Linear (256, 128)\n",
    "        self.fc3 = nn.Linear (128, 10)\n",
    "    def forward(self,x):\n",
    "        #reshape，‘-1’表示自适应\n",
    "        #将前面多维度的tensor展平成一维\n",
    "        x=x.view(x.size()[0],-1)\n",
    "        x=torch.nn.functional.relu(self.fc1(x))\n",
    "        x=torch.nn.functional.relu(self.fc2(x))\n",
    "        x=self.fc3(x)\n",
    "        return x\n",
    "\n",
    "net = MLP()\n",
    "print(net)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### #### 设置数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "batch_size = 256\n",
    "\n",
    "train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### #### 设置参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#损失函数\n",
    "loss = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "#学习率\n",
    "lr=0.5\n",
    "\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### #### 设置迭代次数，开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss 0.0036, train acc 0.660, test acc 0.737\n",
      "epoch 2, loss 0.0019, train acc 0.815, test acc 0.740\n",
      "epoch 3, loss 0.0018, train acc 0.835, test acc 0.741\n",
      "epoch 4, loss 0.0016, train acc 0.851, test acc 0.825\n",
      "epoch 5, loss 0.0014, train acc 0.864, test acc 0.835\n"
     ]
    }
   ],
   "source": [
    "#此处修改迭代次数\n",
    "num_epochs = 5\n",
    "\n",
    "d2l.train_ch3(net, train_iter, test_iter, loss, num_epochs,\n",
    "batch_size, None, None, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
